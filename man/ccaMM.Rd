% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute_CCA_MM.R
\name{ccaMM}
\alias{ccaMM}
\title{Compute CCA
Function to compute CCA using combination of MM algorithm and Gradient Descent.}
\usage{
ccaMM(
  data_x,
  data_y,
  method = "Pearson",
  ...,
  nearPD = FALSE,
  alpha_x = NA,
  alpha_y = NA,
  k = 1,
  tol = 1e-05,
  lr = 0.001,
  epochs = 2000,
  lr_decay = 1,
  criterion = "TPO",
  penalties = NA
)
}
\arguments{
\item{data_x}{An (nxp) data matrix}

\item{data_y}{An (nxq) data matrix}

\item{method}{The selected method for computing the covariance.
Default is "Pearson", referring to the sample covariance, has to be one
of the following: "Spearman", "Kendall", "MCD", "MRCD", "OGK", "pairhuber",
"quadrant", "Ledoit-Wolf".
When a rank-based measure is selected, the covariance is computed as
D . Cor . D, where D is a diagonal matrix containing the column-wise mad.}

\item{...}{Additional parameters to be passed to the covariance estimators}

\item{nearPD}{logical, use Matrix::nearPD() on estimated covariance matrix}

\item{alpha_x}{(1xk) A positive real vector containing numbers between 0 and 1, indicating the elastic
net parameter for data_x for association of order k.}

\item{alpha_y}{(1xk) A positive real vector containing numbers between 0 and 1, indicating the elastic
net parameter for data_y for association of order k.}

\item{k}{highest order of maximum association you want to retrieve}

\item{tol}{desired accuracy for inner loop}

\item{lr}{learning rate for gradient descent algorithm}

\item{epochs}{maximum number of iterations for inner loop}

\item{lr_decay}{learning rate decay for gradient descent algorithm}

\item{criterion}{selection criterion for score function, default is Tradoff Product Optimization, TPO}

\item{penalties}{(optional) if given, no hyperparameter optimization is done,
but the given penalty parameters are used.
They have to be of list structure, containing pen_x and pen_y}
}
\value{
An object of class "CCA_result" that contains following entries:

a A (pxk) vector of the estimated linear combinations
 corresponding to data_x.

b A (qxk) vector of the estimated linear combinations
 corresponding to data_y.

measure A (1xk) vector of the estimated maximum associations

phi A (nxk) matrix of the estimated projections corresponding a * data_x

eta A (nxk) matrix of the estimated projections corresponding b * data_y

pen_x A (1xk) vector of the optimal penalty parameters for data_x

pen_y A (1xk) vector of the optimal penalty parameters for data_y

alpha_x The value of the elastic net parameter alpha_x

alpha_y The value of the elastic net parameter alpha_y

summary A summary of the hyperparameter optimization
}
\description{
Compute CCA
Function to compute CCA using combination of MM algorithm and Gradient Descent.
}
\examples{
\dontrun{
set.seed(123)
library(mvtnorm) # only needed for simulated example
p <- 10
q <- 10
n <- 100

cov_xx <- matrix(0, ncol = p, nrow = p)
cov_yy <- matrix(0, ncol = q, nrow = q)
cov_xy <- matrix(0, nrow = p, ncol = q)

diag(cov_xx) <- 1
diag(cov_yy) <- 1
cov_xy <- matrix(0, nrow = p, ncol = q)
cov_xy[1, 1] <- 0.9
cov_xy[2, 2] <- 0.7

sigma <- rbind(
  cbind(cov_xx, cov_xy),
  cbind(Matrix::t(cov_xy), cov_yy)
)

data <- mvtnorm::rmvnorm(floor(n),
                         mean = rep(0, p + q),
                         sigma = sigma, checkSymmetry = F
)

x <-  as.matrix(data[, 1:p])
y <-  as.matrix(data[, (p + 1):(p + q)])
n_dir <- 2 # we want to derive the first two directions
res <- ccaMM(x, y,
                    k = n_dir,
                    alpha_x = rep(0, n_dir),
                    alpha_y = rep(0, n_dir))
plot(res$a[,1], type = "l")
}
}
