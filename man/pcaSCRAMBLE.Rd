% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute_PCA_SVD.R
\name{pcaSCRAMBLE}
\alias{pcaSCRAMBLE}
\title{Compute PCA
Function to compute PCA using
a modified algorithm combining the MM algorithm and Gradient Descent.
This algorithm is not using the full covariance matrix and instead decomposes
the data matrix to be memory efficient, even in the case of many variables.}
\usage{
pcaSCRAMBLE(
  data_x,
  groups = NA,
  transformation = "identity",
  loss_type = "L2",
  param = NA,
  center = TRUE,
  scale = TRUE,
  alpha_x = NA,
  k = NA,
  tol = 1e-05,
  lr = 0.001,
  epochs = 2000,
  lr_decay = 1,
  criterion = "TPO",
  bounds = c(0.001, 10),
  penalties = NA
)
}
\arguments{
\item{data_x}{An (nxp) data matrix}

\item{groups}{A (1xn) vector containing the groups of the observations}

\item{transformation}{The selected data transformation for the initial estimate.
Default is "identity", this would correspond to using the sample covariance,
has to be one of the following: "spearman", "wrapping"}

\item{loss_type}{The selected type of loss function. Default is "L2", corresponding to a least
squares loss. The type has to be one of the following: "L2", "Huber", "Tukey", "LTS"}

\item{center}{logical: whether data should be centered before proceeding.
Default is "TRUE", using the median}

\item{scale}{logical: whether data should be scaled before proceeding.
Default is "TRUE", using the mad}

\item{alpha_x}{A positive real scalar containing a number between 0 and 1, indicating the elastic
net parameter for data_x for each loading.}

\item{k}{highest order of maximum association you want to retrieve}

\item{tol}{desired accuracy for inner loop}

\item{lr}{learning rate for gradient descent algorithm}

\item{epochs}{maximum number of iterations for inner loop}

\item{lr_decay}{learning rate decay for gradient descent algorithm}

\item{criterion}{selection criterion for score function, default is Tradoff Product Optimization, TPO}

\item{penalties}{(optional) if given, no hyperparameter optimization is done,
but the given penalty parameters are used.
It has to be list structure, containing pen_x to be used for each loading}

\item{...}{Additional parameters to be passed to the loss functions}
}
\value{
An object of class "PCA_result" that contains following entries:

a A (pxk) vector of the estimated loadings

measure A (1xk) vector of the explained variance

phi A (nxk) matrix of the estimated scores corresponding a * data_x

pen_x A (1xk) vector of the optimal penalty parameters for data_x

alpha_x The value of the elastic net parameter alpha_x

summary A summary of the hyperparameter optimization
}
\description{
Compute PCA
Function to compute PCA using
a modified algorithm combining the MM algorithm and Gradient Descent.
This algorithm is not using the full covariance matrix and instead decomposes
the data matrix to be memory efficient, even in the case of many variables.
}
\examples{
\dontrun{
p <- 100
n <- 50
R <- matrix(0, ncol = p, nrow = p)
R[1:4, 1:4] <- 0.9
R[5:8, 5:8] <- 0.5
diag(R) <- 1
V <- diag(c(100, 100, 100, 100, 25, 25, 25, 25, rep(4, p - 8)))
C <- sqrt(V) \%*\% R \%*\% sqrt(V)

set.seed(1)
data <- mvtnorm::rmvnorm(floor(n),
                         mean = rep(0, p),
                         sigma = C)

res_scramble <- pcaSCRAMBLE(data_x = data,
                            groups = NA,
                            transformation = "identity",
                            loss_type = "L2",
                            param = NA,
                            center = TRUE,
                            scale = TRUE,
                            alpha_x = 0,
                            k = 2,
                            tol = 1e-5,
                            lr = 1e-3,
                            epochs = 2000,
                            lr_decay = 0.99,
                            criterion = "TPO",
                            bounds = c(1e-3, 10),
                            penalties = NA)
}
}
